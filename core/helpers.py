import asyncio
import logging
import os
import platform
import re
import signal
import time
from collections.abc import Callable, Coroutine
from fnmatch import fnmatch
from functools import cache, wraps
from pathlib import Path
from sys import stderr
from typing import Any, ParamSpec, TypeVar
from urllib.parse import urlparse

import httpx
from dotenv import load_dotenv

load_dotenv()

# Pre-compiled regex for URL detection - used in URL shortening
URL_PATTERN = re.compile(r'https?://[^\s<>"\']+|www\.[^\s<>"\']+|[^\s<>"\']+\.[a-z]{2,}(?:/[^\s<>"\']*)?', re.IGNORECASE)


logger = logging.getLogger(__name__)


def extract_json_from_text(text: str) -> str:
	"""
	–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤—ã–π –≤–∞–ª–∏–¥–Ω—ã–π JSON-–æ–±—ä–µ–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω –æ–±—ë—Ä–Ω—É—Ç –≤ markdown –∫–æ–¥ –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç.
	–ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Ñ—É–Ω–∫—Ü–∏–∏ extractJSONObject –∏–∑ Rusik Original.
	–¢–∞–∫–∂–µ —É–¥–∞–ª—è–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ (// –∏ /* */) –∏–∑ JSON –ø–µ—Ä–µ–¥ –ø–∞—Ä—Å–∏–Ω–≥–æ–º.
	
	Args:
		text: –¢–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å JSON-–æ–±—ä–µ–∫—Ç
		
	Returns:
		–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π JSON-–æ–±—ä–µ–∫—Ç –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞
		
	Raises:
		ValueError: –ï—Å–ª–∏ JSON-–æ–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
	"""
	import re
	import json as json_module
	
	# –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ markdown –±–ª–æ–∫–∞—Ö –∫–æ–¥–∞
	markdown_json_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
	markdown_match = re.search(markdown_json_pattern, text, re.DOTALL)
	if markdown_match:
		json_str = markdown_match.group(1).strip()
	else:
		# –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ markdown, –∏—â–µ–º –æ–±—ã—á–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç
		depth = 0        # –ì–ª—É–±–∏–Ω–∞ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫
		start = -1       # –ò–Ω–¥–µ–∫—Å –Ω–∞—á–∞–ª–∞ JSON-–æ–±—ä–µ–∫—Ç–∞
		in_string = False  # –ù–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏
		escape = False   # –û–±—Ä–∞–±–æ—Ç–∫–∞ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
		
		for i, ch in enumerate(text):
			if escape:
				escape = False
				continue
				
			if ch == '\\' and in_string:
				escape = True
				continue
			elif ch == '"':
				in_string = not in_string
			elif ch == '{' and not in_string:
				if depth == 0:
					start = i
				depth += 1
			elif ch == '}' and not in_string and depth > 0:
				depth -= 1
				if depth == 0 and start != -1:
					json_str = text[start:i+1]
					break
		else:
			raise ValueError("JSON object not found in text")
	
	# –£–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–∑ JSON –∏—Å–ø–æ–ª—å–∑—É—è –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –∏ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–æ–¥—Ö–æ–¥
	# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å–∏–º–≤–æ–ª–∞–º –∏ —É–¥–∞–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–∫
	result = []
	i = 0
	in_string = False
	escape = False
	
	while i < len(json_str):
		ch = json_str[i]
		
		if escape:
			result.append(ch)
			escape = False
			i += 1
			continue
			
		if ch == '\\' and in_string:
			result.append(ch)
			escape = True
			i += 1
			continue
		elif ch == '"':
			in_string = not in_string
			result.append(ch)
			i += 1
		elif ch == '/' and i + 1 < len(json_str) and not in_string:
			next_ch = json_str[i + 1]
			if next_ch == '/':
				# –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –∫–æ–Ω—Ü–∞ —Ñ–∞–π–ª–∞
				# –í–∞–∂–Ω–æ: –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å–∏–º–≤–æ–ª—ã –¥–æ \n –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ
				while i < len(json_str):
					if json_str[i] == '\n':
						i += 1  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º \n
						break
					i += 1
				continue
			elif next_ch == '*':
				# –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–æ */
				i += 2  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º /*
				while i < len(json_str) - 1:
					if json_str[i] == '*' and json_str[i + 1] == '/':
						i += 2  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º */
						break
					i += 1
				else:
					# –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π */, —ç—Ç–æ –æ—à–∏–±–∫–∞, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
					break
				continue
			else:
				# –≠—Ç–æ –Ω–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –ø—Ä–æ—Å—Ç–æ —Å–∏–º–≤–æ–ª /
				result.append(ch)
				i += 1
		else:
			result.append(ch)
			i += 1
	
	json_str = ''.join(result)
	
	# –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ JSON
	# –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–ø—è—Ç—ã–µ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏
	json_str = re.sub(r',\s*}', '}', json_str)
	json_str = re.sub(r',\s*]', ']', json_str)
	
	# –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏ –≤ –º–∞—Å—Å–∏–≤–∞—Ö
	# –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
	# –ù–∞–ø—Ä–∏–º–µ—Ä: `},      {` –¥–æ–ª–∂–Ω–æ —Å—Ç–∞—Ç—å `},{`
	json_str = re.sub(r'\}\s+,\s+\{', '},{', json_str)  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏ –≤ –º–∞—Å—Å–∏–≤–µ
	json_str = re.sub(r'\}\s+,\s+', '},', json_str)  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–æ–π
	
	# –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å JSON, –ø—ã—Ç–∞—è—Å—å –µ–≥–æ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å
	# –≠—Ç–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
	try:
		# –ü–∞—Ä—Å–∏–º JSON - —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
		parsed = json_module.loads(json_str)
		# –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π JSON (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤)
		return json_module.dumps(parsed, ensure_ascii=False, separators=(',', ':'))
	except json_module.JSONDecodeError as e:
		# –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
		# –£–±–∏—Ä–∞–µ–º trailing commas –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
		json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
		# –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –∑–∞–ø—è—Ç—ã—Ö –≤ –º–∞—Å—Å–∏–≤–∞—Ö (–Ω–æ –Ω–µ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫)
		# –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
		json_str = re.sub(r'\}\s*,\s*\{', '},{', json_str)  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏
		json_str = re.sub(r'\]\s*,\s*\[', '],[', json_str)  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É –º–∞—Å—Å–∏–≤–∞–º–∏
		# –ü—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
		try:
			parsed = json_module.loads(json_str)
			return json_module.dumps(parsed, ensure_ascii=False, separators=(',', ':'))
		except json_module.JSONDecodeError:
			# –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å –∏ –ø—É—Å—Ç—å Pydantic —Ä–∞–∑–±–µ—Ä–µ—Ç—Å—è
			# –ù–æ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
			raise ValueError(f"Failed to parse JSON after comment removal: {e}. JSON string (first 500 chars): {json_str[:500]}")


# Import error types
try:
	from openai import BadRequestError as OpenAIBadRequestError
except ImportError:
	OpenAIBadRequestError = None

try:
	from groq import BadRequestError as GroqBadRequestError  # type: ignore[import-not-found]
except ImportError:
	GroqBadRequestError = None


# Global flag to prevent duplicate exit messages
_exiting = False

# Define generic type variables for return type and parameters
R = TypeVar('R')
T = TypeVar('T')
P = ParamSpec('P')


class SignalHandler:
	"""
	A modular and reusable signal handling system for managing SIGINT (Ctrl+C), SIGTERM,
	and other signals in asyncio applications.

	This class provides:
	- Configurable signal handling for SIGINT and SIGTERM
	- Support for custom pause/resume callbacks
	- Management of event loop state across signals
	- Standardized handling of first and second Ctrl+C presses
	- Cross-platform compatibility (with simplified behavior on Windows)
	"""

	def __init__(
		self,
		loop: asyncio.AbstractEventLoop | None = None,
		pause_callback: Callable[[], None] | None = None,
		resume_callback: Callable[[], None] | None = None,
		custom_exit_callback: Callable[[], None] | None = None,
		exit_on_second_int: bool = True,
		interruptible_task_patterns: list[str] | None = None,
	):
		"""
		Initialize the signal handler.

		Args:
			loop: The asyncio event loop to use. Defaults to current event loop.
			pause_callback: Function to call when system is paused (first Ctrl+C)
			resume_callback: Function to call when system is resumed
			custom_exit_callback: Function to call on exit (second Ctrl+C or SIGTERM)
			exit_on_second_int: Whether to exit on second SIGINT (Ctrl+C)
			interruptible_task_patterns: List of patterns to match task names that should be
										 canceled on first Ctrl+C (default: ['step', 'multi_act', 'get_next_action'])
		"""
		self.loop = loop or asyncio.get_event_loop()
		self.pause_callback = pause_callback
		self.resume_callback = resume_callback
		self.custom_exit_callback = custom_exit_callback
		self.exit_on_second_int = exit_on_second_int
		self.interruptible_task_patterns = interruptible_task_patterns or ['step', 'multi_act', 'get_next_action']
		self.is_windows = platform.system() == 'Windows'

		# Initialize loop state attributes
		self._initialize_loop_state()

		# Store original signal handlers to restore them later if needed
		self.original_sigint_handler = None
		self.original_sigterm_handler = None

	def _initialize_loop_state(self) -> None:
		"""Initialize loop state attributes used for signal handling."""
		setattr(self.loop, 'ctrl_c_pressed', False)
		setattr(self.loop, 'waiting_for_input', False)

	def register(self) -> None:
		"""Register signal handlers for SIGINT and SIGTERM."""
		try:
			if self.is_windows:
				# On Windows, use simple signal handling with immediate exit on Ctrl+C
				def windows_handler(sig, frame):
					print('\n\nüõë Got Ctrl+C. Exiting immediately on Windows...\n', file=stderr)
					# Run the custom exit callback if provided
					if self.custom_exit_callback:
						self.custom_exit_callback()
					os._exit(0)

				self.original_sigint_handler = signal.signal(signal.SIGINT, windows_handler)
			else:
				# On Unix-like systems, use asyncio's signal handling for smoother experience
				self.original_sigint_handler = self.loop.add_signal_handler(signal.SIGINT, lambda: self.sigint_handler())
				self.original_sigterm_handler = self.loop.add_signal_handler(signal.SIGTERM, lambda: self.sigterm_handler())

		except Exception:
			# there are situations where signal handlers are not supported, e.g.
			# - when running in a thread other than the main thread
			# - some operating systems
			# - inside jupyter notebooks
			pass

	def unregister(self) -> None:
		"""Unregister signal handlers and restore original handlers if possible."""
		try:
			if self.is_windows:
				# On Windows, just restore the original SIGINT handler
				if self.original_sigint_handler:
					signal.signal(signal.SIGINT, self.original_sigint_handler)
			else:
				# On Unix-like systems, use asyncio's signal handler removal
				self.loop.remove_signal_handler(signal.SIGINT)
				self.loop.remove_signal_handler(signal.SIGTERM)

				# Restore original handlers if available
				if self.original_sigint_handler:
					signal.signal(signal.SIGINT, self.original_sigint_handler)
				if self.original_sigterm_handler:
					signal.signal(signal.SIGTERM, self.original_sigterm_handler)
		except Exception as e:
			logger.warning(f'Error while unregistering signal handlers: {e}')

	def _handle_second_ctrl_c(self) -> None:
		"""
		Handle a second Ctrl+C press by performing cleanup and exiting.
		This is shared logic used by both sigint_handler and wait_for_resume.
		"""
		global _exiting

		if not _exiting:
			_exiting = True

			# Call custom exit callback if provided
			if self.custom_exit_callback:
				try:
					self.custom_exit_callback()
				except Exception as e:
					logger.error(f'Error in exit callback: {e}')

		# Force immediate exit - more reliable than sys.exit()
		print('\n\nüõë  Got second Ctrl+C. Exiting immediately...\n', file=stderr)

		# Reset terminal to a clean state by sending multiple escape sequences
		# Order matters for terminal resets - we try different approaches

		# Reset terminal modes for both stdout and stderr
		print('\033[?25h', end='', flush=True, file=stderr)  # Show cursor
		print('\033[?25h', end='', flush=True)  # Show cursor

		# Reset text attributes and terminal modes
		print('\033[0m', end='', flush=True, file=stderr)  # Reset text attributes
		print('\033[0m', end='', flush=True)  # Reset text attributes

		# Disable special input modes that may cause arrow keys to output control chars
		print('\033[?1l', end='', flush=True, file=stderr)  # Reset cursor keys to normal mode
		print('\033[?1l', end='', flush=True)  # Reset cursor keys to normal mode

		# Disable bracketed paste mode
		print('\033[?2004l', end='', flush=True, file=stderr)
		print('\033[?2004l', end='', flush=True)

		# Carriage return helps ensure a clean line
		print('\r', end='', flush=True, file=stderr)
		print('\r', end='', flush=True)

		# these ^^ attempts dont work as far as we can tell
		# we still dont know what causes the broken input, if you know how to fix it, please let us know
		print('(tip: press [Enter] once to fix escape codes appearing after chrome exit)', file=stderr)

		os._exit(0)

	def sigint_handler(self) -> None:
		"""
		SIGINT (Ctrl+C) handler.

		First Ctrl+C: Cancel current step and pause.
		Second Ctrl+C: Exit immediately if exit_on_second_int is True.
		"""
		global _exiting

		if _exiting:
			# Already exiting, force exit immediately
			os._exit(0)

		if getattr(self.loop, 'ctrl_c_pressed', False):
			# If we're in the waiting for input state, let the pause method handle it
			if getattr(self.loop, 'waiting_for_input', False):
				return

			# Second Ctrl+C - exit immediately if configured to do so
			if self.exit_on_second_int:
				self._handle_second_ctrl_c()

		# Mark that Ctrl+C was pressed
		setattr(self.loop, 'ctrl_c_pressed', True)

		# Cancel current tasks that should be interruptible - this is crucial for immediate pausing
		self._cancel_interruptible_tasks()

		# Call pause callback if provided - this sets the paused flag
		if self.pause_callback:
			try:
				self.pause_callback()
			except Exception as e:
				logger.error(f'Error in pause callback: {e}')

		# Log pause message after pause_callback is called (not before)
		print('----------------------------------------------------------------------', file=stderr)

	def sigterm_handler(self) -> None:
		"""
		SIGTERM handler.

		Always exits the program completely.
		"""
		global _exiting
		if not _exiting:
			_exiting = True
			print('\n\nüõë SIGTERM received. Exiting immediately...\n\n', file=stderr)

			# Call custom exit callback if provided
			if self.custom_exit_callback:
				self.custom_exit_callback()

		os._exit(0)

	def _cancel_interruptible_tasks(self) -> None:
		"""Cancel current tasks that should be interruptible."""
		active_task = asyncio.current_task(self.loop)
		for running_task in asyncio.all_tasks(self.loop):
			if running_task != active_task and not running_task.done():
				running_task_name = running_task.get_name() if hasattr(running_task, 'get_name') else str(running_task)
				# Cancel tasks that match certain patterns
				if any(pattern in running_task_name for pattern in self.interruptible_task_patterns):
					logger.debug(f'Cancelling task: {running_task_name}')
					running_task.cancel()
					# Add exception handler to silence "Task exception was never retrieved" warnings
					running_task.add_done_callback(lambda t: t.exception() if t.cancelled() else None)

		# Also cancel the current task if it's interruptible
		if active_task and not active_task.done():
			active_task_name = active_task.get_name() if hasattr(active_task, 'get_name') else str(active_task)
			if any(pattern in active_task_name for pattern in self.interruptible_task_patterns):
				logger.debug(f'Cancelling current task: {active_task_name}')
				active_task.cancel()

	def wait_for_resume(self) -> None:
		"""
		Wait for user input to resume or exit.

		This method should be called after handling the first Ctrl+C.
		It temporarily restores default signal handling to allow catching
		a second Ctrl+C directly.
		"""
		# Set flag to indicate we're waiting for input
		setattr(self.loop, 'waiting_for_input', True)

		# Temporarily restore default signal handling for SIGINT
		# This ensures KeyboardInterrupt will be raised during input()
		original_handler = signal.getsignal(signal.SIGINT)
		try:
			signal.signal(signal.SIGINT, signal.default_int_handler)
		except ValueError:
			# we are running in a thread other than the main thread
			# or signal handlers are not supported for some other reason
			pass

		green_color = '\x1b[32;1m'
		red_color = '\x1b[31m'
		blink_code = '\033[33;5m'
		unblink_code = '\033[0m'
		reset_code = '\x1b[0m'

		try:  # escape code is to blink the ...
			print(
				f'‚û°Ô∏è  Press {green_color}[Enter]{reset_code} to resume or {red_color}[Ctrl+C]{reset_code} again to exit{blink_code}...{unblink_code} ',
				end='',
				flush=True,
				file=stderr,
			)
			input()  # This will raise KeyboardInterrupt on Ctrl+C

			# Call resume callback if provided
			if self.resume_callback:
				self.resume_callback()
		except KeyboardInterrupt:
			# Use the shared method to handle second Ctrl+C
			self._handle_second_ctrl_c()
		finally:
			try:
				# Restore our signal handler
				signal.signal(signal.SIGINT, original_handler)
				setattr(self.loop, 'waiting_for_input', False)
			except Exception:
				pass

	def reset(self) -> None:
		"""Reset state after resuming."""
		# Clear the flags
		if hasattr(self.loop, 'ctrl_c_pressed'):
			setattr(self.loop, 'ctrl_c_pressed', False)
		if hasattr(self.loop, 'waiting_for_input'):
			setattr(self.loop, 'waiting_for_input', False)


def time_execution_sync(additional_text: str = '') -> Callable[[Callable[P, R]], Callable[P, R]]:
	def decorator(func: Callable[P, R]) -> Callable[P, R]:
		@wraps(func)
		def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
			begin_time = time.time()
			function_result = func(*args, **kwargs)
			elapsed_time = time.time() - begin_time
			# Only log if execution takes more than 0.25 seconds
			if elapsed_time > 0.25:
				has_logger_in_self = args and getattr(args[0], 'logger', None)
				if has_logger_in_self:
					log_instance = getattr(args[0], 'logger')
				elif 'agent' in kwargs:
					log_instance = getattr(kwargs['agent'], 'logger')
				elif 'browser_session' in kwargs:
					log_instance = getattr(kwargs['browser_session'], 'logger')
				else:
					log_instance = logging.getLogger(__name__)
				log_instance.debug(f'‚è≥ {additional_text.strip("-")}() took {elapsed_time:.2f}s')
			return function_result

		return wrapper

	return decorator


def time_execution_async(
	additional_text: str = '',
) -> Callable[[Callable[P, Coroutine[Any, Any, R]]], Callable[P, Coroutine[Any, Any, R]]]:
	def decorator(func: Callable[P, Coroutine[Any, Any, R]]) -> Callable[P, Coroutine[Any, Any, R]]:
		@wraps(func)
		async def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
			begin_time = time.time()
			function_result = await func(*args, **kwargs)
			elapsed_time = time.time() - begin_time
			# Only log if execution takes more than 0.25 seconds to avoid spamming the logs
			# you can lower this threshold locally when you're doing dev work to performance optimize stuff
			if elapsed_time > 0.25:
				has_logger_in_self = args and getattr(args[0], 'logger', None)
				if has_logger_in_self:
					log_instance = getattr(args[0], 'logger')
				elif 'agent' in kwargs:
					log_instance = getattr(kwargs['agent'], 'logger')
				elif 'browser_session' in kwargs:
					log_instance = getattr(kwargs['browser_session'], 'logger')
				else:
					log_instance = logging.getLogger(__name__)
				log_instance.debug(f'‚è≥ {additional_text.strip("-")}() took {elapsed_time:.2f}s')
			return function_result

		return wrapper

	return decorator


def singleton(class_to_singletonize):
	singleton_instance = [None]

	def wrapper(*args, **kwargs):
		if singleton_instance[0] is None:
			singleton_instance[0] = class_to_singletonize(*args, **kwargs)
		return singleton_instance[0]

	return wrapper


def check_env_variables(keys: list[str], any_or_all=all) -> bool:
	"""Check if all required environment variables are set"""
	return any_or_all(os.getenv(key, '').strip() for key in keys)


def is_unsafe_pattern(pattern: str) -> bool:
	"""
	Check if a domain pattern has complex wildcards that could match too many domains.

	Args:
		pattern: The domain pattern to check

	Returns:
		bool: True if the pattern has unsafe wildcards, False otherwise
	"""
	# Extract domain part if there's a scheme
	if '://' in pattern:
		_, pattern = pattern.split('://', 1)

	# Remove safe patterns (*.domain and domain.*)
	bare_domain = pattern.replace('.*', '').replace('*.', '')

	# If there are still wildcards, it's potentially unsafe
	return '*' in bare_domain


def is_new_tab_page(url: str) -> bool:
	"""
	Check if a URL is a new tab page (about:blank, chrome://new-tab-page, or chrome://newtab).

	Args:
		url: The URL to check

	Returns:
		bool: True if the URL is a new tab page, False otherwise
	"""
	return url in ('about:blank', 'chrome://new-tab-page/', 'chrome://new-tab-page', 'chrome://newtab/', 'chrome://newtab')


def match_url_with_domain_pattern(url: str, domain_pattern: str, log_warnings: bool = False) -> bool:
	"""
	Check if a URL matches a domain pattern. SECURITY CRITICAL.

	Supports optional glob patterns and schemes:
	- *.example.com will match sub.example.com and example.com
	- *google.com will match google.com, agoogle.com, and www.google.com
	- http*://example.com will match http://example.com, https://example.com
	- chrome-extension://* will match chrome-extension://aaaaaaaaaaaa and chrome-extension://bbbbbbbbbbbbb

	When no scheme is specified, https is used by default for security.
	For example, 'example.com' will match 'https://example.com' but not 'http://example.com'.

	Note: New tab pages (about:blank, chrome://new-tab-page) must be handled at the callsite, not inside this function.

	Args:
		url: The URL to check
		domain_pattern: Domain pattern to match against
		log_warnings: Whether to log warnings about unsafe patterns

	Returns:
		bool: True if the URL matches the pattern, False otherwise
	"""
	try:
		# Note: new tab pages should be handled at the callsite, not here
		if is_new_tab_page(url):
			return False

		parsed_url = urlparse(url)

		# Extract only the hostname and scheme components
		url_scheme = parsed_url.scheme.lower() if parsed_url.scheme else ''
		url_domain = parsed_url.hostname.lower() if parsed_url.hostname else ''

		if not url_scheme or not url_domain:
			return False

		# Normalize the domain pattern
		normalized_pattern = domain_pattern.lower()

		# Handle pattern with scheme
		if '://' in normalized_pattern:
			pattern_scheme, pattern_domain = normalized_pattern.split('://', 1)
		else:
			pattern_scheme = 'https'  # Default to matching only https for security
			pattern_domain = normalized_pattern

		# Handle port in pattern (we strip ports from patterns since we already
		# extracted only the hostname from the URL)
		if ':' in pattern_domain and not pattern_domain.startswith(':'):
			pattern_domain = pattern_domain.split(':', 1)[0]

		# If scheme doesn't match, return False
		if not fnmatch(url_scheme, pattern_scheme):
			return False

		# Check for exact match
		if pattern_domain == '*' or url_domain == pattern_domain:
			return True

		# Handle glob patterns
		if '*' in pattern_domain:
			# Check for unsafe glob patterns
			# First, check for patterns like *.*.domain which are unsafe
			if pattern_domain.count('*.') > 1 or pattern_domain.count('.*') > 1:
				if log_warnings:
					log_instance = logging.getLogger(__name__)
					log_instance.error(f'‚õîÔ∏è Multiple wildcards in pattern=[{normalized_pattern}] are not supported')
				return False  # Don't match unsafe patterns

			# Check for wildcards in TLD part (example.*)
			if pattern_domain.endswith('.*'):
				if log_warnings:
					log_instance = logging.getLogger(__name__)
					log_instance.error(f'‚õîÔ∏è Wildcard TLDs like in pattern=[{normalized_pattern}] are not supported for security')
				return False  # Don't match unsafe patterns

			# Then check for embedded wildcards
			domain_without_wildcard = pattern_domain.replace('*.', '')
			if '*' in domain_without_wildcard:
				if log_warnings:
					log_instance = logging.getLogger(__name__)
					log_instance.error(f'‚õîÔ∏è Only *.domain style patterns are supported, ignoring pattern=[{normalized_pattern}]')
				return False  # Don't match unsafe patterns

			# Special handling so that *.google.com also matches bare google.com
			if pattern_domain.startswith('*.'):
				base_domain = pattern_domain[2:]
				if url_domain == base_domain or fnmatch(url_domain, base_domain):
					return True

			# Normal case: match domain against pattern
			if fnmatch(url_domain, pattern_domain):
				return True

		return False
	except Exception as e:
		log_instance = logging.getLogger(__name__)
		log_instance.error(f'‚õîÔ∏è Error matching URL {url} with pattern {domain_pattern}: {type(e).__name__}: {e}')
		return False


def merge_dicts(target_dict: dict, source_dict: dict, merge_path: tuple[str, ...] = ()):
	for merge_key in source_dict:
		if merge_key in target_dict:
			if isinstance(target_dict[merge_key], dict) and isinstance(source_dict[merge_key], dict):
				merge_dicts(target_dict[merge_key], source_dict[merge_key], merge_path + (str(merge_key),))
			elif isinstance(target_dict[merge_key], list) and isinstance(source_dict[merge_key], list):
				target_dict[merge_key] = target_dict[merge_key] + source_dict[merge_key]
			elif target_dict[merge_key] != source_dict[merge_key]:
				raise Exception('Conflict at ' + '.'.join(merge_path + (str(merge_key),)))
		else:
			target_dict[merge_key] = source_dict[merge_key]
	return target_dict


@cache
def get_agent_version() -> str:
	"""Get the version of the current project (from pyproject.toml if it exists)."""
	try:
		project_root = Path(__file__).parent.parent
		pyproject_file = project_root / 'pyproject.toml'

		if pyproject_file.exists():
			import re

			with open(pyproject_file, encoding='utf-8') as file_handle:
				file_content = file_handle.read()
				version_match = re.search(r'version\s*=\s*["\']([^"\']+)["\']', file_content)
				if version_match:
					version_string = f'{version_match.group(1)}'
					os.environ['LIBRARY_VERSION'] = version_string
					return version_string
	except Exception as e:
		logger.debug(f'Error determining project version: {type(e).__name__}: {e}')
		return 'unknown'
	return 'unknown'


async def check_latest_agent_version() -> str | None:
	"""Stub: checking latest version on PyPI is disabled."""
	return None


@cache
def get_git_info() -> dict[str, str] | None:
	"""Get git information if installed from git repository"""
	try:
		import subprocess

		package_root = Path(__file__).parent.parent
		git_dir = package_root / '.git'
		if not git_dir.exists():
			return None

		# Get git commit hash
		commit_hash = (
			subprocess.check_output(['git', 'rev-parse', 'HEAD'], cwd=package_root, stderr=subprocess.DEVNULL).decode().strip()
		)

		# Get git branch
		branch = (
			subprocess.check_output(['git', 'rev-parse', '--abbrev-ref', 'HEAD'], cwd=package_root, stderr=subprocess.DEVNULL)
			.decode()
			.strip()
		)

		# Get remote URL
		remote_url = (
			subprocess.check_output(['git', 'config', '--get', 'remote.origin.url'], cwd=package_root, stderr=subprocess.DEVNULL)
			.decode()
			.strip()
		)

		# Get commit timestamp
		commit_timestamp = (
			subprocess.check_output(['git', 'show', '-s', '--format=%ci', 'HEAD'], cwd=package_root, stderr=subprocess.DEVNULL)
			.decode()
			.strip()
		)

		return {'commit_hash': commit_hash, 'branch': branch, 'remote_url': remote_url, 'commit_timestamp': commit_timestamp}
	except Exception as e:
		logger.debug(f'Error getting git info: {type(e).__name__}: {e}')
		return None


def _log_pretty_path(path: str | Path | None) -> str:
	"""Pretty-print a path, shorten home dir to ~ and cwd to ."""

	if not path or not str(path).strip():
		return ''  # always falsy in -> falsy out so it can be used in ternaries

	# dont print anything thats not a path
	if not isinstance(path, (str, Path)):
		# no other types are safe to just str(path) and log to terminal unless we know what they are
		# e.g. what if we get storage_date=dict | Path and the dict version could contain real cookies
		return f'<{type(path).__name__}>'

	# replace home dir and cwd with ~ and .
	pretty_path = str(path).replace(str(Path.home()), '~').replace(str(Path.cwd().resolve()), '.')

	# wrap in quotes if it contains spaces
	if pretty_path.strip() and ' ' in pretty_path:
		pretty_path = f'"{pretty_path}"'

	return pretty_path


def _log_pretty_url(s: str, max_len: int | None = 22) -> str:
	"""Truncate/pretty-print a URL with a maximum length, removing the protocol and www. prefix"""
	s = s.replace('https://', '').replace('http://', '').replace('www.', '')
	if max_len is not None and len(s) > max_len:
		return s[:max_len] + '‚Ä¶'
	return s


def create_task_with_error_handling(
	coro: Coroutine[Any, Any, T],
	*,
	name: str | None = None,
	logger_instance: logging.Logger | None = None,
	suppress_exceptions: bool = False,
) -> asyncio.Task[T]:
	"""
	Create an asyncio task with proper exception handling to prevent "Task exception was never retrieved" warnings.

	Args:
		coro: The coroutine to wrap in a task
		name: Optional name for the task (useful for debugging)
		logger_instance: Optional logger instance to use. If None, uses module logger.
		suppress_exceptions: If True, logs exceptions at ERROR level. If False, logs at WARNING level
			and exceptions remain retrievable via task.exception() if the caller awaits the task.
			Default False.

	Returns:
		asyncio.Task: The created task with exception handling callback

	Example:
		# Fire-and-forget with suppressed exceptions
		create_task_with_error_handling(some_async_function(), name="my_task", suppress_exceptions=True)

		# Task with retrievable exceptions (if you plan to await it)
		task = create_task_with_error_handling(critical_function(), name="critical")
		result = await task  # Will raise the exception if one occurred
	"""
	task = asyncio.create_task(coro, name=name)
	log = logger_instance or logger

	def _handle_task_exception(t: asyncio.Task[T]) -> None:
		"""Callback to handle task exceptions"""
		exc_to_raise = None
		try:
			# This will raise if the task had an exception
			exc = t.exception()
			if exc is not None:
				task_name = t.get_name() if hasattr(t, 'get_name') else 'unnamed'
				if suppress_exceptions:
					# –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –º–æ–≥—É—Ç –ø–∞–¥–∞—Ç—å - —ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–≥–¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è)
					log.debug(f'Exception in background task [{task_name}]: {type(exc).__name__}: {exc}', exc_info=exc)
				else:
					# Log at debug level then mark for re-raising (—ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á)
					log.debug(
						f'Exception in background task [{task_name}]: {type(exc).__name__}: {exc}',
						exc_info=exc,
					)
					exc_to_raise = exc
		except asyncio.CancelledError:
			# Task was cancelled, this is normal behavior
			pass
		except Exception as e:
			# Catch any other exception during exception handling (e.g., t.exception() itself failing)
			task_name = t.get_name() if hasattr(t, 'get_name') else 'unnamed'
			# –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫ debug, —Ç.–∫. —ç—Ç–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
			log.debug(f'Error handling exception in task [{task_name}]: {type(e).__name__}: {e}')

		# Re-raise outside the try-except block so it propagates to the event loop
		if exc_to_raise is not None:
			raise exc_to_raise

	task.add_done_callback(_handle_task_exception)
	return task


def sanitize_surrogates(text: str) -> str:
	"""Remove surrogate characters that can't be encoded in UTF-8.

	Surrogate pairs (U+D800 to U+DFFF) are invalid in UTF-8 when unpaired.
	These often appear in DOM content from mathematical symbols or emojis.

	Args:
		text: The text to sanitize

	Returns:
		Text with surrogate characters removed
	"""
	return text.encode('utf-8', errors='ignore').decode('utf-8')
